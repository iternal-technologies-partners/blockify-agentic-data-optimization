# Supporting a Top 3 Oil and Gas Company’s Operations through Improving LLM Accuracy by 78x with Blockify and AirgapAI

AI is rapidly becoming a strategic asset for the Energy industry. To enhance operational efficiency, ensure safety compliance, and improve the general accuracy of remote site operations, engineers and field operators must access the right information, at the right time, in a safe, secure, and trusted manner \- while being absolutely certain every insight is factually correct and within the rules, regulations, and legal frameworks provided.

# AutoReports
## Enterprise-Scale Document Analysis and Automation — No Code Required

---

## The Problem: Document Analysis Doesn't Scale with Humans

Enterprises are drowning in documents. Legal contracts, security questionnaires, procurement proposals, regulatory filings, and compliance documentation pile up faster than teams can read them.

The manual approach breaks down at scale:
- **Bottlenecked throughput**: A lawyer spends 30-90 minutes reviewing a single contract — multiply that by thousands
- **Missed value**: Rebate clauses, renegotiation windows, and compliance deadlines buried in dense text go unnoticed
- **Inconsistent quality**: Human-dependent accuracy varies by analyst, fatigue level, and time pressure
- **Revenue risk**: Security questionnaires not returned on time kill deals; contracts renewed "as-is" lock in outdated terms
- **Impossible economics**: Reviewing 2 million pages manually requires tens of thousands of labor hours per month

**The result: critical insights stay buried, deadlines get missed, and organizations leave millions of dollars on the table.**

---

## The Solution: AutoReports Enterprise Document Analysis

AutoReports is a **no-code, AI-powered document analysis and automation platform** that ingests, structures, analyzes, and generates outputs from massive volumes of documents — at enterprise scale.

Instead of manually reading documents one at a time, AutoReports processes them through configurable LLM workflows that extract exactly the insights your teams need.

**The numbers speak for themselves:**

| Metric | Result |
|--------|--------|
| **Processing Speed** | ~46 pages of text per minute per core |
| **Monthly Throughput** | ~2 million pages on a single Gaudi 2 core |
| **Cost Reduction** | Up to 95.2% vs. manual methods |
| **Time Savings** | Up to 85% reduction in active work time |
| **Accuracy** | 90-95%+ validated draft quality |
| **Annual Hours Saved** | 62,500 - 97,250 hours (proven at scale) |

---

## How AutoReports Works

### The Processing Pipeline

| Step | What Happens |
|------|--------------|
| **1. Document Ingestion** | Accept DOCX, PDF, TXT, emails, spreadsheets, scanned images, and other media formats |
| **2. Blockification** | Patented Blockify technology breaks documents into verified "IdeaBlocks" with rich metadata — improving LLM accuracy by up to 78X |
| **3. Configurable LLM Workflow** | User-defined prompts and queries extract specific insights — no coding required |
| **4. Multi-Model Processing** | Different sections can leverage different LLMs (standard or fine-tuned) for specialized analysis |
| **5. Output Generation** | Structured outputs as DOCX, JSON, spreadsheets, or API responses |
| **6. Review & Finalization** | Human expert reviews AI-generated draft — minutes instead of hours |

### What Makes AutoReports Different

- **No-code workflows**: Business users configure analysis pipelines without engineering support
- **Multi-model architecture**: Different parts of a report can tap into 1, 2, 3+ unique LLMs for specialized processing
- **IdeaBlock-level processing**: Queries execute at the block level, enabling granular, accurate extraction
- **Bulk API**: Process entire libraries of documents through high-volume batch operations
- **Bring Your Own Model**: Plug in the latest GenAI LLMs for maximum performance

---

## The Business Case: Proven ROI Across Industries

### Legal: Contract Analysis & Document Drafting

| Scenario | Manual Cost | AutoReports Cost | Savings |
|----------|-------------|------------------|---------|
| **Case Argument Letter Drafting** | $337.50/document (67.5 min @ $300/hr) | $45.48/document (10 min review) | 86.53% |
| **Contract Review (16 pages)** | 30 min lawyer time | 20.88 seconds processing | 62,500 hrs/year saved |
| **Legal Document Drafting** | $XXX/document | $XX/document | ~86% cost reduction |

*A single Gaudi 8X server can support an entire enterprise legal department.*

### Security & Compliance: Questionnaire Processing

| Scenario | Manual Cost | AutoReports Cost | Savings |
|----------|-------------|------------------|---------|
| **Security Requirement Response** | $15/requirement (10 min) | $2.10/requirement (30 sec) | 95%+ |
| **Policy Draft** | $45/policy (30 min) | Included in response cost | Combined savings |
| **161-Question Questionnaire** | 64.83 hours | ~336 seconds | 97,250 hrs/year saved |

*Top-3 global shipping company validated 95%+ accuracy with sub-second per-question latency.*

### Engineering & Geotechnical: PDF Data Extraction

| Scenario | Manual Cost | AutoReports Cost | Savings |
|----------|-------------|------------------|---------|
| **PDF Data Extraction per Page** | ~10 minutes manual entry | 0.0075 seconds | 95.2% cost reduction |
| **Scale Target** | Limited by headcount | 500,000+ documents | Enterprise-ready |

*Dual-LLM pipeline (Gemini 2.5 + GPT-4.1) converts varied PDF templates into normalized JSON.*

---

## Use Cases by Department

### Legal Operations & In-House Counsel

| Use Case | What AutoReports Does |
|----------|-----------------------|
| **Contract Term Extraction** | Automatically identify payment schedules, termination clauses, liability limits, rebate terms |
| **Compliance Gap Analysis** | Flag missing/outdated clauses for GDPR, CCPA, FDA/EMA, ESG requirements |
| **Document Drafting** | Generate 90%+ quality drafts of argument letters, demand letters, compliance filings |
| **M&A Due Diligence** | Parse acquired company contracts, assess synergy/risk factors, accelerate integration |
| **Renewal & Renegotiation Tracking** | Proactive alerts on expiring agreements and renegotiation windows |
| **Redline Generation** | AI-powered contract redlines with good/better/best fallback positions |

### Security & Compliance Teams

| Use Case | What AutoReports Does |
|----------|-----------------------|
| **Security Questionnaire Response** | Map requirements to policies and generate draft answers automatically |
| **Policy Draft Generation** | Create new draft policies to fill identified security gaps |
| **Gap Analysis** | Highlight where controls don't satisfy customer standards (ISO 27001, NIST, SOC 2) |
| **Vendor Security Assessment** | Score third-party vendor controls against your security baseline |
| **Audit Readiness** | Generate export-ready compliance statements mapped to regulatory mandates |

### Procurement & Supply Chain

| Use Case | What AutoReports Does |
|----------|-----------------------|
| **RFP/RFI Processing** | Extract must-have specs and compliance terms from vendor proposals |
| **Pricing Analysis** | Match negotiated unit prices and volume discounts across suppliers |
| **Supplier Contract Management** | Delineate shipping terms, penalty clauses, SLAs across thousands of vendor contracts |
| **Equipment Lease Analysis** | Summarize lease timelines, extension options, SLA details |

### Finance & Business Operations

| Use Case | What AutoReports Does |
|----------|-----------------------|
| **Rebate Recovery** | Identify and track unclaimed rebates, incentives, and service credits |
| **Financial Term Extraction** | Extract payment schedules, penalty structures, price-break clauses |
| **Portfolio Analytics** | Executive dashboards with risk heat maps, renewal pipelines, BU scorecards |

---

## Performance Benchmarks

### Processing Speed (LLAMA 3.1 70B on Intel Gaudi)

| Document Type | Size | Processing Time | Tokens Generated |
|---------------|------|-----------------|------------------|
| **Supplier Agreement** | 12 pages (3,003 words) | 15.85 seconds | 426 tokens |
| **Legal Contract** | 16 pages (3,068 words) | 20.88 seconds | 478 tokens |
| **Legal Contract** | 8 pages (1,534 words) | 19.05 seconds | 426 tokens |
| **Security Questionnaire** | 161 questions (49,377 words) | 336 seconds | 6,850 tokens |

### Throughput Metrics

| Metric | Value |
|--------|-------|
| **Response Time per Token** | 22-27 tokens/second |
| **Pages per Minute** | ~46 |
| **Contract Queries per Month** | 124,000 - 166,000 |
| **Pages Processed per Month** | ~2 million (single Gaudi 2 core) |

---

## Platform Flexibility

### Supported LLM Models

| Category | Options |
|----------|---------|
| **On-Premises** | LLAMA 3.1 (8B, 70B), LLAMA 3.2 (1B, 3B), any open-source model |
| **Cloud APIs** | Google Gemini 2.5 (Flash Lite, Pro), OpenAI GPT-4.1 (Nano, Full), or comparable Tier 1 LLMs |
| **Custom** | Bring Your Own Model — including fine-tuned variants |

### Supported Input Formats

| Format | Types |
|--------|-------|
| **Documents** | DOCX, PDF, TXT, Markdown, HTML |
| **Presentations** | PPT |
| **Spreadsheets** | CSV, XLSX |
| **Media** | PNG, JPG (via multimodal extraction) |
| **Email** | Standard email formats |

### Compute Infrastructure

| Platform | Options |
|----------|---------|
| **AI Accelerators** | Intel Gaudi 2/3, NVIDIA GPU, AMD GPU |
| **CPU** | Intel Xeon |
| **Edge/Offline** | Intel NPU (via AirgapAI) |

---

## Architecture & Integration

AutoReports integrates seamlessly into existing enterprise systems:

| Integration Point | Examples |
|--------------------|----------|
| **Contract Management** | CLM platforms, document management systems |
| **ERP** | SAP, Oracle, and other enterprise resource planning systems |
| **CRM** | Salesforce, HubSpot, and other customer relationship platforms |
| **Storage** | AWS S3, Azure Blob, on-premises file systems |
| **Workflow Triggers** | API events, S3 uploads, DMS status changes |

### API-First Design

- **Bulk API** for high-volume batch processing
- **OpenAPI standard** format
- **Zero Trust security** and role-based access
- **Real-time updates** and version control
- **Integration in hours** — not weeks

---

## Deployment Options

| Option | Description | Best For |
|--------|-------------|----------|
| **Cloud SaaS** | Hosted AutoReports processing | Fast deployment, minimal IT overhead |
| **Private Cloud** | AutoReports in customer's cloud environment | Data residency requirements |
| **On-Premises** | Full installation behind firewall with Intel Gaudi | Classified/air-gapped environments |
| **Hybrid** | Cloud processing with on-prem storage | Balanced security and convenience |

---

## Implementation Journey

| Phase | Activities | Outcome |
|-------|------------|---------|
| **Pilot** | Define use case, configure workflows, process sample documents | Validated ROI and accuracy metrics |
| **Production Setup** | Professional services deployment, pipeline configuration, system integration | Production-ready environment |
| **Knowledge Base Curation** | Curate source documentation, build IdeaBlock taxonomies | Optimized data foundation |
| **Scale** | Expand document volumes, add use cases, onboard departments | Enterprise-wide deployment |
| **Ongoing Optimization** | Monitor accuracy, update workflows, expand model capabilities | Continuous improvement |

---

## Services Opportunities

| Service | Description |
|---------|-------------|
| **Pilot Program** | Validate ROI with a scoped document set and use case |
| **Production Deployment** | Professional services to deploy full production pipeline |
| **Advanced PDF Data Extraction** | Automated extraction pipeline for complex/scanned documents |
| **Knowledge Base Curation** | Build and maintain the source documentation corpus |
| **Custom Workflow Development** | Configure specialized LLM workflows for unique use cases |
| **System Integration** | Connect AutoReports to existing CRM, ERP, DMS, and CLM platforms |
| **Ongoing Optimization** | Accuracy monitoring, workflow updates, model upgrades |

---

## The Bottom Line

AutoReports solves the fundamental problem limiting enterprise document operations: **human throughput doesn't scale, AI does.**

| Challenge | AutoReports Solution |
|-----------|---------------------|
| **Manual document review** | 2 million pages/month on a single server |
| **Slow turnaround** | Seconds per document instead of hours |
| **High labor costs** | Up to 95.2% cost reduction |
| **Inconsistent quality** | 90-95%+ validated accuracy |
| **Missed deadlines** | Automated alerts and prioritized queues |
| **Revenue at risk** | Never miss a questionnaire deadline or renegotiation window |
| **Impossible scale** | 62,500 - 97,250 hours saved annually |

**AutoReports converts manual, error-prone document workflows into automated, accurate, enterprise-scale operations — without writing a single line of code.**

---

*AutoReports is developed by Iternal Technologies, powering enterprise AI for Fortune 500 companies, global shipping leaders, top pharmaceutical companies, and legal organizations worldwide.*

**Enterprise Sales**: sales@iternal.ai
**Website**: iternal.ai
**Technical Support**: support@iternal.ai

---

*Patents pending. AutoReports, Blockify, IdeaBlock, and AirgapAI are trademarks of Iternal Technologies.*


Intel and Iternal Technologies have partnered to provide a unique solution that addresses the most common challenges energy companies face when adopting AI technologies: hallucinations, data curation, governance, and ultra-granular access-control of sensitive and restricted data.

Pairing highly performant data-center solutions like Gaudi 2/Xeon & Blockify® for data preparation and optimization with edge-based Intel NPU chips & AirgapAI™ software for 100 percent local inference delivers an end-to-end platform that allows company personnel to draft compliant reports, answer technical inquiries, and surface operational documentation \- with 78X greater accuracy.

## **Benchmark Results**

The Top 3 Oil and Gas Company’s 404 page operational and safety handbooks contains 70,881 words of essential conduct materials that must be processed.  
Depending on business and technology objectives there are multiple methods to process the information, using Intel AI PCs, Intel Xeon, or Intel Gaudi 2\.

### Intel Core Ultra 7 265V:

Leveraging Intel Core Ultra 7 265V AI PC CPU, processing is completed in about 35,441 seconds. The ability to process 4,860 pages of text per month (2 words per second) on a Intel Core Ultra 7 265V AI PC CPU demonstrates the ability to start small and scale.

* Total Time: ≈ 35441 seconds  
* Total Responses: ≈ 496 chunks

### Intel Xeon 6767P:

Leveraging Intel Xeon 6767P Series 6 CPUs, processing is completed in about 844 seconds. The ability to process 622 thousand pages of text per month (84 words per second) on a single Xeon 6767P CPU demonstrates the scalability and efficiency of this approach on non-GPU hardware.

* Total Time: ≈ 844 seconds  
* Total Responses: ≈ 496 chunks

### Intel Gaudi 2:

Leveraging Gaudi 2, processing is completed in about 105 seconds. The ability to process 5 million pages of text per month (675 words per second) on a single Gaudi 2 core demonstrates the scalability and efficiency of this approach.

* Total Time: ≈ 105 seconds  
* Total Responses: ≈ 496 chunks

Beyond speed, Blockify’s approach increased the precision of vector searches and RAG models, virtually eliminating hallucinations and improving LLM accuracy by approximately 78× (7,800 percent) compared with a traditional RAG pipeline.

## **Why AI Inference Matters and Why You Should Care**

AI inference is more than running a trained model; it goes beyond simple document search. It empowers energy teams to process real-time, accurate, and contextually relevant insights from critical operational and safety procedures at scale.  
Traditional operation efforts require manual research across countless repositories. Without an AI-driven content-lifecycle approach, Energy Organizations risk delays, non-compliant actions, or accidents in field operations. Garbage in, garbage out \- and if you can’t trust your AI every time, you can’t trust it at all.

![][image2]

Intel and Iternal used AI to bring structure to unstructured documents: maintenance logs, sensor data, safety incident reports, and operational guidelines, through an advanced data-ingestion and optimization approach powered by Blockify.

![][image3]

The result is a single source of truth distilled to only 2.5 percent of its original size \- easier to govern, quicker to query, and fully aligned to export-control rules.

## **A Summary of the AI Inference Solution**

### Blockify Data Ingestion with Gaudi

Leveraging Intel Gaudi 2 AI accelerators / Xeon CPUs and Iternal’s patented Blockify solution, Major Energy Company teams can ingest and optimize thousands of documents for an improved large-language-model inferencing pipeline paired with RAG.

* Processing Speed: ≈ 900 words / sec  
* Accuracy: RAG-based LLM accuracy ↑ 40×; vector search precision ↑ 51 %  
* Inference Throughput: 0.68 inferences / sec (≈ 5,404 bytes / sec)

Blockify’s three-pronged ingestion, distillation, and taxonomy workflow:

* Ingestion \- Extract essential information from source.  
* Distillation \- eliminate redundant clauses, legacy specs, and obsolete standards.  
* Taxonomy Creation \- index every block for dynamic contextual retrieval

### AirgapAI – Inferencing at the Edge with Intel NPU

Optimizing data is only useful when applied in the field. AirgapAI is a powerful, network-independent AI solution designed to run locally on Intel-equipped AI PCs within a company’s secure environment – no external connectivity required.

* Vector Search & Inference: ≈ 2.2× faster on Intel NPU, enabling quicker analysis of large datasets.  
* Accuracy: RAG-based LLM accuracy ↑ 40×; vector search precision ↑ 51%, leading to more reliable information for engineers and improved safety compliance.  
* Retrieval: Scan ≈ 10 million records in \< 1.5 sec, allowing rapid access to critical information for operational efficiency and support.

After Blockify outputs the distilled dataset, operators load it onto an AirgapAI-enabled workstation. The system retrieves relevant content and launches an LLM inference to draft accurate responses to technical inquiries, ensure safety-checked incident reports, or generate compliant internal communications – all fully offline, ensuring OSHA and other relevant data security standards are met.  
![][image4]

By operating completely offline, AirgapAI upholds stringent data-protection standards, as no external connection is required, minimizing potential vulnerabilities and ensuring confidential operational data remains strictly private.

As LLMs become more powerful and less compute intensive, the Intel Core line of chips is able to maximize the performance and utilization of highly efficient models with improved LLM accuracy. However accuracy only can be improved if the quality of the data is high. Garbage in, garbage out.

![][image5]

## **ROI and Cost Benefits**

The deployment of this AI solution is projected to deliver a transformative financial impact. Over a three-year period, the company is expected to realize a total net benefit of $45,747,000, achieving a remarkable 708.9% return on investment. The initial AI deployment cost of $6,453,000 is projected to be recovered in just 4.45 months, driven by significant operational savings.

* Projected Total Net Benefit: $45,747,000 over 3 years  
* Projected Return on Investment (ROI): 708.9%  
* Projected Payback Period: 4.45 months  
* Projected Total Savings: $52,200,000 (from $36,000,000 in downtime savings and $16,200,000 in safety savings)  
* Projected Operational Improvements: 1% reduction in equipment downtime and a 2% reduction in safety incidents.

![][image6]

These projections highlight the substantial value driven by enhancing predictive maintenance and safety procedures. By focusing on integrating equipment data, the company can maximize its return, positioning itself as an industry leader in both efficiency and safety.

## **Eliminating Legacy RAG Pitfalls**

A core challenge for energy companies is how engineers phrase questions and the overwhelming volume of information within technical documents. Our AI solution addresses these issues by delivering a 51 percent improvement in the accuracy of retrieved information. It achieves this by focusing on the core intent of a query and guiding the system toward the most relevant content, thereby enhancing operational efficiency, safety compliance, and the general accuracy of remote site operations.

![][image7]

## **What We Did: Breaking Down the Framework**

Intel Gaudi 2 / Xeon accelerates LLM inference with high-throughput deep-learning cores, ideal for parallel processing of complex, multi-tiered technical and safety documentation. The Major Energy Company’s documents often contain nested specifications and acronym-heavy language. To enable real-time Q\&A, content was modularized with Blockify, then embedded as high-density vectors for instantaneous retrieval.

LLAMA 3, fine-tuned via Low-Rank Adaptation (LoRA) on a single Gaudi 2 core or Xeon Chip, achieved optimal quality by processing 8,000-character segments and generating 1,000 tokens per response with 100 parallel jobs.

### The Blockify workflow steps included:

1. Chunking the Text: The source documents were divided into smaller content chunks based on a proprietary algorithm. Those chunks were passed into the specially configured LLM, which output modular blocks of content. These blocks offer a robust taxonomy that can be reused or reassembled based on user needs.

![][image8]

2. Embeddings: These content blocks were converted into embeddings (vector representations)  
   to capture unique context and structure, enabling content-aware retrieval within AirgapAI.  
3. Retrieval and Response Generation: Based on user queries, the system retrieves relevant content from the Context-Aware Retrieval Database for accurate, contextually relevant responses.

This enhanced workflow allows instant recall of insights, strategies, policies, dynamically assembling content into diverse outputs using large language models. The result is real-time expertise, engagement, and personalized content in minutes, saving hours of manual work.

### Business Use Cases: Real-Time AI Inference in Action

* Technical Query Response \- assemble detailed responses to common technical questions about equipment specifications, maintenance schedules, or safety procedures in minutes while ensuring data privacy rules are met.  
* Safety Compliance Audits \- auto-populate incident reports with lineage-tracked safety procedures and regulatory precedents.  
* Internal & Partner Briefings \- produce legally compliant, publicly releasable marketing collateral for joint venture programs without exposing sensitive source data.  
* Field Operations Assistant \- field real-time questions from operators on protocol deviations, jurisdiction boundaries, or emergency response metrics entirely offline.  
* Training Procedure Authoring \- draft qualification training plans referencing historical incident outcomes or operational feedback in seconds.

### What This Means for You: Scalable AI Inference for Future Growth

By uniting Intel Gaudi 2 / Xeon and Iternal Technologies’ Blockify with the secure, offline capabilities of AirgapAI, Energy Companies can harness AI inference at scale, turning decades of unstructured operational data into actionable insights without ever exposing sensitive information to third-party clouds. With Intel Gaudi 2/Xeon, Blockify, and AirgapAI, a Major Energy Company can:

* Automate Data Ingestion & Curation \- process terabytes of legacy documentation while slashing inaccuracies.  
* Drive Hyper-Compliant Content \- ensure every generated paragraph respects privacy, legal, and departmental guidelines.  
* Accelerate Decision-Making \- surface trusted answers in seconds, compressing response times and boosting public trust.  
* Protect Operational Data \- keep all sensitive data within the company’s secure network, eliminating cloud-based exposure risks.

AI has moved from conceptual to operational in the energy sector. Whether generating a rapid-response internal communication, answering technical inquiries, or drafting operational procedures, Intel and Iternal deliver the secure, accurate, and scalable framework a Major Energy Company needs to maintain mission advantage.  









