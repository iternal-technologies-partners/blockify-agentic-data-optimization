# Blockify Distillation Service - Environment Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# REQUIRED: API Keys
# =============================================================================

# Blockify API key for LLM merging operations
# Get your key from: https://app.blockify.ai/settings/api
BLOCKIFY_API_KEY=

# OpenAI API key for embeddings
# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=

# =============================================================================
# SERVER CONFIGURATION
# =============================================================================

# Server host and port
HOST=0.0.0.0
PORT=8315

# Logging level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================

# Database backend: sqlite, postgresql, redis, filesystem
DATABASE_BACKEND=sqlite

# Database connection URL (varies by backend)
# SQLite:     sqlite:///./data/jobs.db
# PostgreSQL: postgresql://user:password@host:5432/dbname
# Redis:      redis://host:6379/0
DATABASE_URL=sqlite:///./data/jobs.db

# Data directory for filesystem storage and SQLite
DATA_DIR=./data

# =============================================================================
# JOB CONFIGURATION
# =============================================================================

# Enable automatic cleanup of old jobs (default: disabled)
JOB_RETENTION_ENABLED=false

# Days to retain completed jobs (if retention enabled)
JOB_RETENTION_DAYS=30

# Maximum job execution time in seconds (default: ~166 hours)
JOB_TIMEOUT_SECONDS=600000

# Number of concurrent job workers
MAX_WORKERS=5

# =============================================================================
# ALGORITHM CONFIGURATION
# =============================================================================

# Maximum blocks per LLM merge call
MAX_CLUSTER_SIZE_FOR_LLM=20

# Maximum blocks per cluster (before hierarchical splitting)
MAX_BLOCKS_PER_CLUSTER=20

# Parallel threads for LLM calls
LLM_PARALLEL_THREADS=5

# LLM retry configuration
LLM_MAX_RETRIES=3
LLM_RETRY_DELAY=2.0

# Use Locality-Sensitive Hashing for large datasets
USE_LSH=true

# Similarity threshold configuration
SIMILARITY_INCREASE_PER_ITERATION=0.01
MAX_SIMILARITY_THRESHOLD=0.98

# =============================================================================
# OBSERVABILITY
# =============================================================================

# Enable Prometheus metrics at /metrics
PROMETHEUS_ENABLED=true

# Enable OpenTelemetry tracing
OTLP_ENABLED=false

# OpenTelemetry collector endpoint (if OTLP_ENABLED=true)
OTLP_ENDPOINT=

# Enable debug logging for LLM calls
LLM_DEBUG=false

# =============================================================================
# API CONFIGURATION (Optional)
# =============================================================================

# Blockify API base URL (default: production)
# BLOCKIFY_BASE_URL=https://api.blockify.ai/v1

# OpenAI embeddings endpoint (default: production)
# OPENAI_EMBEDDING_URL=https://api.openai.com/v1/embeddings

# Embedding model to use
# EMBEDDING_MODEL_NAME=text-embedding-3-small
